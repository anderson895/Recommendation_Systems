{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXQzH0nC5JtP"
   },
   "source": [
    "# **Project: Amazon Product Recommendation System**\n",
    "\n",
    "# **Marks: 40**\n",
    "\n",
    "\n",
    "Welcome to the project on Recommendation Systems. We will work with the Amazon product reviews dataset for this project. The dataset contains ratings of different electronic products. It does not include information about the products or reviews to avoid bias while building the model. \n",
    "\n",
    "--------------\n",
    "## **Context:**\n",
    "--------------\n",
    "\n",
    "Today, information is growing exponentially with volume, velocity and variety throughout the globe. This has lead to information overload, and too many choices for the consumer of any business. It represents a real dilemma for these consumers and they often turn to denial. Recommender Systems are one of the best tools that help recommending products to consumers while they are browsing online. Providing personalized recommendations which is most relevant for the user is what's most likely to keep them engaged and help business. \n",
    "\n",
    "E-commerce websites like Amazon, Walmart, Target and Etsy use different recommendation models to provide personalized suggestions to different users. These companies spend millions of dollars to come up with algorithmic techniques that can provide personalized recommendations to their users.\n",
    "\n",
    "Amazon, for example, is well-known for its accurate selection of recommendations in its online site. Amazon's recommendation system is capable of intelligently analyzing and predicting customers' shopping preferences in order to offer them a list of recommended products. Amazon's recommendation algorithm is therefore a key element in using AI to improve the personalization of its website. For example, one of the baseline recommendation models that Amazon uses is item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.\n",
    "\n",
    "----------------\n",
    "## **Objective:**\n",
    "----------------\n",
    "\n",
    "You are a Data Science Manager at Amazon, and have been given the task of building a recommendation system to recommend products to customers based on their previous ratings for other products. You have a collection of labeled data of Amazon reviews of products. The goal is to extract meaningful insights from the data and build a recommendation system that helps in recommending products to online consumers.\n",
    "\n",
    "-----------------------------\n",
    "## **Dataset:** \n",
    "-----------------------------\n",
    "\n",
    "The Amazon dataset contains the following attributes:\n",
    "\n",
    "- **userId:** Every user identified with a unique id\n",
    "- **productId:** Every product identified with a unique id\n",
    "- **Rating:** The rating of the corresponding product by the corresponding user\n",
    "- **timestamp:** Time of the rating. We **will not use this column** to solve the current problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmdPxJ2Q7W7p"
   },
   "source": [
    "**Note:** The code has some user defined functions that will be usefull while making recommendations and measure model performance, you can use these functions or can create your own functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoRfgjS2yekq"
   },
   "source": [
    "Sometimes, the installation of the surprise library, which is used to build recommendation systems, faces issues in Jupyter. To avoid any issues, it is advised to use **Google Colab** for this project.\n",
    "\n",
    "Let's start by mounting the Google drive on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "id": "GZ0YAszcT4zK"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ibk07-Cyekt"
   },
   "source": [
    "**Installing surprise library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "id": "05HQoiZYlsbB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in c:\\users\\padilla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\padilla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-surprise) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\padilla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-surprise) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\padilla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-surprise) (1.10.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fIt4jcFIm76"
   },
   "source": [
    "## **Importing the necessary libraries and overview of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "id": "jzu2P-TT5JtP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    AKM1MP6P0OYPR  132793040  5  1365811200\n",
      "0  A2CX7LUOHB2NDG  321732944  5  1341100800\n",
      "1  A2NWSAGRHCP8N5  439886341  1  1367193600\n",
      "2  A2WNBOD3WNDNKT  439886341  3  1374451200\n",
      "3  A1GI0U4ZRJA8WN  439886341  1  1334707200\n",
      "4  A1QGNMC6O1VW39  511189877  5  1397433600\n",
      "Index(['AKM1MP6P0OYPR', '132793040', '5', '1365811200'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "\n",
    "# Load the data\n",
    "file_path = 'ratings_Electronics.csv'  \n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Display the column names\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrXYJAv95JtP"
   },
   "source": [
    "### **Loading the data**\n",
    "- Import the Dataset\n",
    "- Add column names ['user_id', 'prod_id', 'rating', 'timestamp']\n",
    "- Drop the column timestamp\n",
    "- Copy the data to another DataFrame called **df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "id": "JGb-Hk1B5JtP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          user_id    prod_id  rating\n",
      "0   AKM1MP6P0OYPR  132793040       5\n",
      "1  A2CX7LUOHB2NDG  321732944       5\n",
      "2  A2NWSAGRHCP8N5  439886341       1\n",
      "3  A2WNBOD3WNDNKT  439886341       3\n",
      "4  A1GI0U4ZRJA8WN  439886341       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'ratings_Electronics.csv'  # Replace with your file path\n",
    "\n",
    "\n",
    "# Load the dataset and add column names\n",
    "column_names = ['user_id', 'prod_id', 'rating', 'timestamp']\n",
    "data = pd.read_csv(file_path, names=column_names, header=None)\n",
    "\n",
    "# Dropping the 'timestamp' column\n",
    "data.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "# Creating a copy of the DataFrame\n",
    "df = data.copy()\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVQnSG5g_9uX"
   },
   "source": [
    "**These observations indicate that the dataset comprises user interactions with different products, providing ratings on a scale of 1 to 5. This information will be crucial for building a recommendation system, as it reflects how users perceive and rate different products in the dataset.\r\n",
    "\r\n",
    "\r\n",
    ".**\n",
    "\n",
    "\n",
    "Here, we will be taking users who have given at least 50 ratings, and the products that have at least 5 ratings, as when we shop online we prefer to have some number of ratings of a product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "id": "4yt9W7Q32EQQ"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the users\n",
    "users = df.user_id\n",
    "\n",
    "# Create a dictionary from users to their number of ratings\n",
    "ratings_count = dict()\n",
    "\n",
    "for user in users:\n",
    "\n",
    "    # If we already have the user, just add 1 to their rating count\n",
    "    if user in ratings_count:        \n",
    "        ratings_count[user] += 1\n",
    "  \n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[user] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "id": "19XB60dq2EQR"
   },
   "outputs": [],
   "source": [
    "# We want our users to have at least 50 ratings to be considered\n",
    "RATINGS_CUTOFF = 50\n",
    "\n",
    "remove_users = []\n",
    "\n",
    "for user, num_ratings in ratings_count.items():\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_users.append(user)\n",
    "\n",
    "df = df.loc[ ~ df.user_id.isin(remove_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "id": "33UzK1D82EQS"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the products\n",
    "prods = df.prod_id\n",
    "\n",
    "# Create a dictionary from products to their number of ratings\n",
    "ratings_count = dict()\n",
    "\n",
    "for prod in prods:\n",
    "    \n",
    "    # If we already have the product, just add 1 to its rating count\n",
    "    if prod in ratings_count:\n",
    "        ratings_count[prod] += 1\n",
    "    \n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[prod] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "id": "u6YE-lUp2EQT"
   },
   "outputs": [],
   "source": [
    "# We want our item to have at least 5 ratings to be considered\n",
    "RATINGS_CUTOFF = 5\n",
    "\n",
    "remove_users = []\n",
    "\n",
    "for user, num_ratings in ratings_count.items():\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_users.append(user)\n",
    "\n",
    "df_final = df.loc[~ df.prod_id.isin(remove_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "id": "aL1JZ00o5JtQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40261</th>\n",
       "      <td>ALUNVOQRXOZIA</td>\n",
       "      <td>B00004SB92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40361</th>\n",
       "      <td>A1JWSDDIH5Z7DV</td>\n",
       "      <td>B00004SB92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40411</th>\n",
       "      <td>A5JLAU2ARJ0BO</td>\n",
       "      <td>B00004SB92</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40702</th>\n",
       "      <td>A1RPTVW5VEOSI</td>\n",
       "      <td>B00004SB92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40823</th>\n",
       "      <td>A231WM2Z2JL0U3</td>\n",
       "      <td>B00004SB92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_id     prod_id  rating\n",
       "40261   ALUNVOQRXOZIA  B00004SB92       1\n",
       "40361  A1JWSDDIH5Z7DV  B00004SB92       5\n",
       "40411   A5JLAU2ARJ0BO  B00004SB92       4\n",
       "40702   A1RPTVW5VEOSI  B00004SB92       5\n",
       "40823  A231WM2Z2JL0U3  B00004SB92       5"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a few rows of the imported dataset\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuPoy_XfxhXZ"
   },
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0d0bWeG-sVB"
   },
   "source": [
    "### **Shape of the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyBVTRDTyek0"
   },
   "source": [
    "### **Check the number of rows and columns and provide observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "id": "fJ4eQKaY5JtQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 3456\n",
      "Number of Columns: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows and columns and provide observations\n",
    "data_shape = df.shape\n",
    "print(\"Number of Rows:\", data_shape[0])\n",
    "print(\"Number of Columns:\", data_shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Slp-fgWQ-sVD"
   },
   "source": [
    "**Write your observations here:Observing the shape of the data can give you insight into the data you're handling and what the next step in analyzing it might be. ****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAMWm0nC-sVF"
   },
   "source": [
    "### **Data types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "id": "SVrgMkye5JtQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    object\n",
      "prod_id    object\n",
      "rating      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of each column\n",
    "data_types = df.dtypes\n",
    "print(data_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4fOE02D-sVF"
   },
   "source": [
    "**Write your observations here:** There are several columns with 'object' data types, which usually represent string data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTMpOROT-sVG"
   },
   "source": [
    "### **Checking for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "id": "vt-VEjMA5JtQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    0\n",
      "prod_id    0\n",
      "rating     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values present and provide observations\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMWuBNhI5JtR"
   },
   "source": [
    "**Write your observations here:** No other columns exhibit missing values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wETrCg48-sVG"
   },
   "source": [
    "### **Summary Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "id": "tYm30MXR5JtR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3456.000000\n",
      "mean        4.222801\n",
      "std         1.137754\n",
      "min         1.000000\n",
      "25%         4.000000\n",
      "50%         5.000000\n",
      "75%         5.000000\n",
      "max         5.000000\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics of the 'rating' variable\n",
    "rating_stats = df['rating'].describe()\n",
    "print(rating_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqW50EIJxhXc"
   },
   "source": [
    "**Write your observations here:* The quartile information offers insights into the distribution of ratings***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywyFrZIf5JtR"
   },
   "source": [
    "### **Checking the rating distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "id": "QbqhbEVe-sVH"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you want to plot the distribution of ratings, replace 'rating' with the column you want to plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "df['rating'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Percentage of Total')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0jONrQv-sVH"
   },
   "source": [
    "**Write your observations here:Most ratings tend to be towards the higher end are 5, indicating a positive bias in user reviews.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HefpLdLJxhXd"
   },
   "source": [
    "### **Checking the number of unique users and items in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "id": "NbSom7195JtR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the final data =  3456\n",
      "Number of unique USERS in Raw data =  38\n",
      "Number of unique ITEMS in Raw data =  2943\n"
     ]
    }
   ],
   "source": [
    "print('The number of observations in the final data = ', len(df))\n",
    "print('Number of unique USERS in Raw data = ', df['user_id'].nunique())\n",
    "print('Number of unique ITEMS in Raw data = ', df['prod_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qwgz6CUt-sVI"
   },
   "source": [
    "**Write your observations here:Most ratings tend to be towards the higher end are 5, indicating a positive bias in user reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfDnhSS4-sVI"
   },
   "source": [
    "### **Users with the most number of ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "id": "n7MX452q5JtR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "A5JLAU2ARJ0BO     5\n",
       "A1F9Z42CFF9IAY    3\n",
       "A1MJMYLRTZ76ZX    3\n",
       "A231WM2Z2JL0U3    3\n",
       "A1FR68QH6Z4YZM    2\n",
       "A1VQHH85U7PX0     2\n",
       "A2B7BUH8834Y6M    2\n",
       "A12DLJESJKM1OQ    1\n",
       "A2XRMQA6PJ5ZJ8    1\n",
       "AT6CZDCP4TRGA     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 users based on the number of ratings\n",
    "most_rated = df_final.groupby('user_id').size().sort_values(ascending = False)[:10]\n",
    "most_rated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1X2w_jt9-sVI"
   },
   "source": [
    "**Write your observations here:These observations reveal the varying degrees of engagement among the top users and emphasize the standout user contributing the highest count of ratings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnYTx-Ol-sVg"
   },
   "source": [
    "**Now that we have explored and prepared the data, let's build the first recommendation system.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xYGrGVy5JtS"
   },
   "source": [
    "## **Model 1: Rank Based Recommendation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "id": "yxZTj1UPxhXh",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Average_Rating  Rating_Count\n",
      "prod_id                                 \n",
      "B0009VNE0S             5.0             1\n",
      "B0002ZA7I8             5.0             1\n",
      "B00008VFCS             5.0             1\n",
      "B000EXS1BS             5.0             1\n",
      "B00008VF7U             5.0             1\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average rating for each product\n",
    "average_rating = df.groupby('prod_id')['rating'].mean()\n",
    "\n",
    "# Calculate the count of ratings for each product\n",
    "count_rating = df.groupby('prod_id')['rating'].count()\n",
    "\n",
    "# Create a dataframe with calculated average and count of ratings\n",
    "final_rating = pd.DataFrame({'Average_Rating': average_rating, 'Rating_Count': count_rating})\n",
    "\n",
    "# Sort the dataframe by average of ratings in descending order\n",
    "final_rating = final_rating.sort_values(by='Average_Rating', ascending=False)\n",
    "\n",
    "# See the first five records of the \"final_rating\" dataset\n",
    "print(final_rating.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "id": "zKU__5s1xhXi"
   },
   "outputs": [],
   "source": [
    "# Defining a function to get the top n products based on the highest average rating and minimum interactions\n",
    "def top_n_products(final_rating, n, min_interaction):\n",
    "    # Finding products with minimum number of interactions\n",
    "    min_interactions = final_rating[final_rating['Rating_Count'] >= min_interaction]\n",
    "    \n",
    "    # Sorting values with respect to average rating\n",
    "    recommendations = min_interactions.sort_values(by='Average_Rating', ascending=False)\n",
    "    \n",
    "    return recommendations.index[:n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8l6373PxhXi"
   },
   "source": [
    "### **Recommending top 5 products with 50 minimum interactions based on popularity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "id": "dBxdLiM_xhXi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 products with a minimum of 50 interactions based on popularity:\n",
      "Index([], dtype='object', name='prod_id')\n"
     ]
    }
   ],
   "source": [
    "# Call the function to get the top 5 products with a minimum of 50 interactions\n",
    "top_5_50_interactions = top_n_products(final_rating, n=5, min_interaction=50)\n",
    "\n",
    "print(\"Top 5 products with a minimum of 50 interactions based on popularity:\")\n",
    "print(top_5_50_interactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9_xW_UMxhXj"
   },
   "source": [
    "### **Recommending top 5 products with 100 minimum interactions based on popularity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "id": "dZgGZCUoxhXj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 products with a minimum of 100 interactions based on popularity:\n",
      "Index([], dtype='object', name='prod_id')\n"
     ]
    }
   ],
   "source": [
    "# Call the function to get the top 5 products with a minimum of 100 interactions\n",
    "top_5_100_interactions = top_n_products(final_rating, n=5, min_interaction=100)\n",
    "\n",
    "print(\"Top 5 products with a minimum of 100 interactions based on popularity:\")\n",
    "print(top_5_100_interactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL-m68a15JtT",
    "outputId": "69132b0f-8d3f-4798-f6a0-249e17a3c822"
   },
   "source": [
    "We have recommended the **top 5** products by using the popularity recommendation system. Now, let's build a recommendation system using **collaborative filtering.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJI5kiiGvOOK"
   },
   "source": [
    "## **Model 2: Collaborative Filtering Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skzc0N1_nVNB"
   },
   "source": [
    "### **Building a baseline user-user similarity based recommendation system**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Uo_MYMnVNB"
   },
   "source": [
    "- Below, we are building **similarity-based recommendation systems** using `cosine` similarity and using **KNN to find similar users** which are the nearest neighbor to the given user.  \n",
    "- We will be using a new library, called `surprise`, to build the remaining models. Let's first import the necessary classes and functions from this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "id": "UJ1wEylUpexj"
   },
   "outputs": [],
   "source": [
    "# To compute the accuracy of models\n",
    "from surprise import accuracy\n",
    "\n",
    "# Class is used to parse a file containing ratings, data should be in structure - user ; item ; rating\n",
    "from surprise.reader import Reader\n",
    "\n",
    "# Class for loading datasets\n",
    "from surprise.dataset import Dataset\n",
    "\n",
    "# For tuning model hyperparameters\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# For splitting the rating data in train and test datasets\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# For implementing similarity-based recommendation system\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# For implementing matrix factorization based recommendation system\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# for implementing K-Fold cross-validation\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "# For implementing clustering-based recommendation system\n",
    "from surprise import CoClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54MqVAtDTsnl"
   },
   "source": [
    "**Before building the recommendation systems, let's  go over some basic terminologies we are going to use:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qsxb3xhnTsnl"
   },
   "source": [
    "**Relevant item:** An item (product in this case) that is actually **rated higher than the threshold rating** is relevant, if the **actual rating is below the threshold then it is a non-relevant item**.  \n",
    "\n",
    "**Recommended item:** An item that's **predicted rating is higher than the threshold is a recommended item**, if the **predicted rating is below the threshold then that product will not be recommended to the user**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moyLUHCuTsnl"
   },
   "source": [
    "**False Negative (FN):** It is the **frequency of relevant items that are not recommended to the user**. If the relevant items are not recommended to the user, then the user might not buy the product/item. This would result in the **loss of opportunity for the service provider**, which they would like to minimize.\n",
    "\n",
    "**False Positive (FP):** It is the **frequency of recommended items that are actually not relevant**. In this case, the recommendation system is not doing a good job of finding and recommending the relevant items to the user. This would result in **loss of resources for the service provider**, which they would also like to minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yuvc2VaZTsnl"
   },
   "source": [
    "**Recall:** It is the **fraction of actually relevant items that are recommended to the user**, i.e., if out of 10 relevant products, 6 are recommended to the user then recall is 0.60. Higher the value of recall better is the model. It is one of the metrics to do the performance assessment of classification models.\n",
    "\n",
    "**Precision:** It is the **fraction of recommended items that are relevant actually**, i.e., if out of 10 recommended items, 6 are found relevant by the user then precision is 0.60. The higher the value of precision better is the model. It is one of the metrics to do the performance assessment of classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NLc36Y8Tsnm"
   },
   "source": [
    "**While making a recommendation system, it becomes customary to look at the performance of the model. In terms of how many recommendations are relevant and vice-versa, below are some most used performance metrics used in the assessment of recommendation systems.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqF8fRBqTsnm"
   },
   "source": [
    "### **Precision@k, Recall@ k, and F1-score@k**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imMJNF0HTsnm"
   },
   "source": [
    "**Precision@k** - It is the **fraction of recommended items that are relevant in `top k` predictions**. The value of k is the number of recommendations to be provided to the user. One can choose a variable number of recommendations to be given to a unique user.  \n",
    "\n",
    "\n",
    "**Recall@k** - It is the **fraction of relevant items that are recommended to the user in `top k` predictions**.\n",
    "\n",
    "**F1-score@k** - It is the **harmonic mean of Precision@k and Recall@k**. When **precision@k and recall@k both seem to be important** then it is useful to use this metric because it is representative of both of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBW4BUhWTsnm"
   },
   "source": [
    "### **Some useful functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOBHKh0eTsnm"
   },
   "source": [
    "- Below function takes the **recommendation model** as input and gives the **precision@k, recall@k, and F1-score@k** for that model.  \n",
    "- To compute **precision and recall**, **top k** predictions are taken under consideration for each user.\n",
    "- We will use the precision and recall to compute the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "id": "Rxn-GahOTsnm"
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_k(model, k = 10, threshold = 3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user\n",
    "    user_est_true = defaultdict(list)\n",
    "    \n",
    "    # Making predictions on the test data\n",
    "    predictions = model.test(testset)\n",
    "    \n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key = lambda x: x[0], reverse = True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. Therefore, we are setting Precision to 0 when n_rec_k is 0\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. Therefore, we are setting Recall to 0 when n_rel is 0\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    \n",
    "    # Mean of all the predicted precisions are calculated.\n",
    "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
    "    \n",
    "    # Mean of all the predicted recalls are calculated.\n",
    "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
    "    \n",
    "    accuracy.rmse(predictions)\n",
    "    \n",
    "    print('Precision: ', precision) # Command to print the overall precision\n",
    "    \n",
    "    print('Recall: ', recall) # Command to print the overall recall\n",
    "    \n",
    "    print('F_1 score: ', round((2*precision*recall)/(precision+recall), 3)) # Formula to compute the F-1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZmsamDVyek-"
   },
   "source": [
    "**Hints:**\n",
    "\n",
    "- To compute **precision and recall**, a **threshold of 3.5 and k value of 10 can be considered for the recommended and relevant ratings**.\n",
    "- Think about the performance metric to choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hxjJMTwnVNB"
   },
   "source": [
    "Below we are loading the **`rating` dataset**, which is a **pandas DataFrame**, into a **different format called `surprise.dataset.DatasetAutoFolds`**, which is required by this library. To do this, we will be **using the classes `Reader` and `Dataset`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "id": "rGfYDiOCpe4X"
   },
   "outputs": [],
   "source": [
    "# Instantiating Reader scale with expected rating scale\n",
    "\n",
    "# Loading the rating dataset\n",
    "\n",
    "# Splitting the data into train and test datasets\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Instantiating Reader scale with the expected rating scale (assuming it ranges from 1 to 5)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Loading the rating dataset into the Surprise format\n",
    "data = Dataset.load_from_df(df[['user_id', 'prod_id', 'rating']], reader)\n",
    "\n",
    "# Splitting the data into train and test datasets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmHTEt7TnVNC"
   },
   "source": [
    "Now, we are **ready to build the first baseline similarity-based recommendation system** using the cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVDfVHB4tQfU"
   },
   "source": [
    "### **Building the user-user Similarity-based Recommendation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "id": "vO3FL7iape8A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1368\n",
      "Precision:  0.828\n",
      "Recall:  0.68\n",
      "F_1 score:  0.747\n"
     ]
    }
   ],
   "source": [
    "# Declaring the similarity options\n",
    "\n",
    "\n",
    "# Initialize the KNNBasic model using sim_options declared, Verbose = False, and setting random_state = 1\n",
    "\n",
    "\n",
    "# Fit the model on the training data\n",
    "\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score using the precision_recall_at_k function defined above\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "from surprise import accuracy\n",
    "\n",
    "# Convert Surprise trainset and testset to pandas DataFrame\n",
    "train_df = pd.DataFrame(trainset.build_testset(), columns=['user_id', 'prod_id', 'rating'])\n",
    "test_df = pd.DataFrame(testset, columns=['user_id', 'prod_id', 'rating'])\n",
    "\n",
    "# Sample a smaller subset of the data\n",
    "\n",
    "# Sample a smaller subset of the data with replacement\n",
    "sampled_train = train_df.sample(n=8000, replace=True, random_state=42)  # Adjust the size as needed\n",
    "\n",
    "# Sample a smaller subset of the test data with replacement\n",
    "sampled_test = test_df.sample(n=2000, replace=True, random_state=42)  # Adjust the size as needed\n",
    "\n",
    "# Convert the sampled data back to surprise trainset and testset\n",
    "sampled_trainset = Dataset.load_from_df(sampled_train, reader).build_full_trainset()\n",
    "sampled_testset = Dataset.load_from_df(sampled_test, reader).build_full_trainset().build_testset()\n",
    "\n",
    "# Initialize the KNNBasic model\n",
    "sim_options = {'name': 'cosine', 'user_based': True}\n",
    "sim_user_user = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
    "\n",
    "# Fit the model on the sampled training data\n",
    "sim_user_user.fit(sampled_trainset)\n",
    "\n",
    "# Compute precision@k, recall@k, and F1-score using the precision_recall_at_k function\n",
    "precision_recall_at_k(sim_user_user, k=10, threshold=3.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEuJK_A9Tsnn"
   },
   "source": [
    "**Write your observations here:The current model performs reasonably well, but further iterations, adjustments, or trying different algorithms could help in achieving a more accurate and efficient recommendation system.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reFD0-nsnVNC"
   },
   "source": [
    "Let's now **predict rating for a user with `userId=A3LDPF5FMB782Z` and `productId=1400501466`** as shown below. Here the user has already interacted or watched the product with productId '1400501466' and given a rating of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sxd23bZ9pe_x"
   },
   "outputs": [],
   "source": [
    "# Predicting rating for a sample user with an interacted product\n",
    "predicted_rating = sim_user_user.predict(\"A3LDPF5FMB782Z\", \"1400501466\", r_ui=5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENJcqG_wemRH"
   },
   "source": [
    "**Write your observations here:The prediction could not be made successfully, and the predicted rating deviates from the actual rating.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cj6ecbglTsno"
   },
   "source": [
    "Below is the **list of users who have not seen the product with product id \"1400501466\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCRBMD-RTsno"
   },
   "outputs": [],
   "source": [
    "# Filter unique user IDs with prod_id not equal to \"1400501466\"\n",
    "unique_users_with_other_products = df.loc[df['prod_id'] != '1400501466', 'user_id'].unique()\n",
    "\n",
    "print(unique_users_with_other_products)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KT42ecaSTsno"
   },
   "source": [
    "* It can be observed from the above list that **user \"A34BZM6S9L7QI4\" has not seen the product with productId \"1400501466\"** as this userId is a part of the above list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXSgq8OEnVNE"
   },
   "source": [
    "**Below we are predicting rating for `userId=A34BZM6S9L7QI4` and `prod_id=1400501466`.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbFcBj1PpfEV"
   },
   "outputs": [],
   "source": [
    "# Predicting rating for a sample user with a non interacted product\n",
    "predicted_rating = sim_user_user.predict(\"A34BZM6S9L7QI4\", \"1400501466\", r_ui=None, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02rwld8yemRI"
   },
   "source": [
    "**Write your observations here:This suggests that, based on the model's calculations, user 'A34BZM6S9L7QI4' might provide a rating of around 4.05 to the product '1400501466' if they were to interact with it. However, this is just a prediction, and the actual user rating may vary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejjof6csnVNF"
   },
   "source": [
    "### **Improving similarity-based recommendation system by tuning its hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2j4VvfQnVNF"
   },
   "source": [
    "Below, we will be tuning hyperparameters for the `KNNBasic` algorithm. Let's try to understand some of the hyperparameters of the KNNBasic algorithm:\n",
    "\n",
    "- **k** (int) – The (max) number of neighbors to take into account for aggregation. Default is 40.\n",
    "- **min_k** (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set to the global mean of all ratings. Default is 1.\n",
    "- **sim_options** (dict) – A dictionary of options for the similarity measure. And there are four similarity measures available in surprise - \n",
    "    - cosine\n",
    "    - msd (default)\n",
    "    - Pearson\n",
    "    - Pearson baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LmPbSUSTsnp"
   },
   "outputs": [],
   "source": [
    "# Setting up parameter grid to tune the hyperparameters\n",
    "\n",
    "# Performing 3-fold cross-validation to tune the hyperparameters\n",
    "\n",
    "# Fitting the data\n",
    "\n",
    "# Best RMSE score\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import KNNBasic\n",
    "import random\n",
    "\n",
    "# Instantiate Reader scale with expected rating scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the rating dataset into the Surprise format\n",
    "data = Dataset.load_from_df(df[['user_id', 'prod_id', 'rating']], reader)\n",
    "\n",
    "# Split the data into train and test datasets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sample a smaller subset of the data\n",
    "sample_size = 10000  # Define the sample size\n",
    "sampled_users = random.sample(trainset.all_users(), k=sample_size)  # Sample 'sample_size' users\n",
    "sampled_ratings = []\n",
    "\n",
    "# Extract ratings for the sampled users\n",
    "for user in sampled_users:\n",
    "    user_ratings = trainset.ur[user]\n",
    "    sampled_ratings.extend((user, item, rating) for (item, rating) in user_ratings)\n",
    "\n",
    "# Reconstruct the trainset after sampling\n",
    "sampled_trainset = Dataset.load_from_df(pd.DataFrame(sampled_ratings, columns=['user_id', 'prod_id', 'rating']), reader)\n",
    "\n",
    "# Initialize the KNNBasic model\n",
    "sim_options = {'name': 'cosine', 'user_based': True}\n",
    "sim_user_user = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
    "\n",
    "# Fit the model on the sampled training data\n",
    "sim_user_user.fit(sampled_trainset.build_full_trainset())\n",
    "\n",
    "# Compute precision@k, recall@k, and F1-score using the precision_recall_at_k function\n",
    "precision_recall_at_k(sim_user_user, k=10, threshold=3.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2fHNvu7nVNF"
   },
   "source": [
    "Once the grid search is **complete**, we can get the **optimal values for each of those hyperparameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHWgxu_YnVNG"
   },
   "source": [
    "Now, let's build the **final model by using tuned values of the hyperparameters**, which we received by using **grid search cross-validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "id": "PujRJA8X_JEJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4775\n",
      "MAE:  1.2202\n",
      "RMSE: 1.4775052189719704\n",
      "MAE: 1.2202466041666666\n"
     ]
    }
   ],
   "source": [
    "# Using the optimal similarity measure for user-user based collaborative filtering\n",
    "\n",
    "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
    "\n",
    "# Training the algorithm on the trainset\n",
    "\n",
    "# Let us compute precision@k and recall@k also with k =10\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'ratings_Electronics.csv'\n",
    "\n",
    "# Read a smaller subset of the data\n",
    "sampled_dataset = pd.read_csv(file_path, nrows=10000)  # Adjust the number of rows as needed\n",
    "\n",
    "# Initialize the reader object\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "# Load the data into Surprise dataset\n",
    "data = Dataset.load_from_df(sampled_dataset[['AKM1MP6P0OYPR', '132793040', '5']], reader)\n",
    "\n",
    "\n",
    "# Split the data into train and test sets (80% train, 20% test)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Define the algorithm (KNNBasic with optimal hyperparameters)\n",
    "sim_options = {\n",
    "    'name': 'cosine',  # Using cosine similarity (you can change this if needed)\n",
    "    'user_based': True  # User-user collaborative filtering\n",
    "}\n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Train the algorithm on the trainset (using the smaller subset)\n",
    "knn.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = knn.test(testset)\n",
    "\n",
    "# Calculate RMSE and MAE (optional)\n",
    "from surprise.accuracy import rmse, mae\n",
    "rmse_score = rmse(predictions)\n",
    "mae_score = mae(predictions)\n",
    "print(f\"RMSE: {rmse_score}\")\n",
    "print(f\"MAE: {mae_score}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHsWvFjKTsnp"
   },
   "source": [
    "**It's also important to consider the context of your application and the specific requirements while interpreting these error values..**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhcAXK0CnVNG"
   },
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "id": "FgV63lHiq1TV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Predicted rating for user A3LDPF5FMB782Z and product 1400501466 using the optimized model: 2.975\n"
     ]
    }
   ],
   "source": [
    "# Use sim_user_user_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId 1400501466\n",
    "\n",
    "from surprise import KNNBasic\n",
    "\n",
    "# Assuming you have a reader and data loaded\n",
    "\n",
    "# Create a KNNBasic model with the necessary options\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True\n",
    "}\n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(data.build_full_trainset())  # Assuming 'data' is your Surprise dataset\n",
    "\n",
    "# Now you can predict ratings using the model\n",
    "predicted_rating_optimized = knn.predict(user_id, prod_id).est\n",
    "print(f\"Predicted rating for user {user_id} and product {prod_id} using the optimized model: {predicted_rating_optimized}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "id": "HXO2Ztjhq1bN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A34BZM6S9L7QI4 and product 1400501466 using the 'sim_user_user_optimized' model: 3.972989533414396\n"
     ]
    }
   ],
   "source": [
    "# Use sim_user_user_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "# User and product details for prediction\n",
    "user_id = \"A34BZM6S9L7QI4\"\n",
    "prod_id = \"1400501466\"\n",
    "\n",
    "# Predict rating for user \"A34BZM6S9L7QI4\" and product \"1400501466\" using the 'sim_user_user_optimized' model\n",
    "predicted_rating_optimized = sim_user_user_optimized.predict(user_id, prod_id).est\n",
    "print(f\"Predicted rating for user {user_id} and product {prod_id} using the 'sim_user_user_optimized' model: {predicted_rating_optimized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5i-OPprNF2e"
   },
   "source": [
    "**These predicted ratings offer insights into the model's estimations of how well a particular user might like a specific product, considering their interaction history and patterns within the dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op_zwO_FnVNH"
   },
   "source": [
    "### **Identifying similar users to a given user (nearest neighbors)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2QsfqhanVNH"
   },
   "source": [
    "We can also find out **similar users to a given user** or its **nearest neighbors** based on this KNNBasic algorithm. Below, we are finding the 5 most similar users to the first user in the list with internal id 0, based on the `msd` distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "id": "TbFle7cKmBJG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "The 5 most similar users to user with inner ID 0 are: [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# 0 is the inner id of the above user\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "\n",
    "# Assuming you have the necessary dataset 'data' loaded in Surprise\n",
    "\n",
    "# Initialize the KNNBasic algorithm with the required options\n",
    "sim_options = {\n",
    "    'name': 'msd',  # Using the 'msd' distance metric\n",
    "    'user_based': True\n",
    "}\n",
    "knn_basic = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Fit the model on the dataset\n",
    "knn_basic.fit(data.build_full_trainset())\n",
    "\n",
    "# Get 5 most similar users to the first user with inner ID 0\n",
    "user_inner_id = 0  # Inner ID of the user\n",
    "k_neighbors = knn_basic.get_neighbors(user_inner_id, k=5)  # Get 5 most similar users\n",
    "\n",
    "print(f\"The 5 most similar users to user with inner ID 0 are: {k_neighbors}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0NsrX_anVNH"
   },
   "source": [
    "### **Implementing the recommendation algorithm based on optimized KNNBasic model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3ESobDynVNI"
   },
   "source": [
    "Below we will be implementing a function where the input parameters are:\n",
    "\n",
    "- data: A **rating** dataset\n",
    "- user_id: A user id **against which we want the recommendations**\n",
    "- top_n: The **number of products we want to recommend**\n",
    "- algo: the algorithm we want to use **for predicting the ratings**\n",
    "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "id": "vW9V1Tk65HlY"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(data, user_id, top_n, algo):\n",
    "    # Creating an empty list to store the recommended product ids\n",
    "    recommendations = []\n",
    "    \n",
    "    # Creating an empty dictionary to map product IDs to their ratings for a specific user\n",
    "    user_ratings = {}\n",
    "    \n",
    "    # Loop through the whole dataset to get user-item interactions\n",
    "    for user, item, actual_rating in data.build_full_trainset().all_ratings():\n",
    "        if user == user_id:\n",
    "            user_ratings[item] = algo.predict(user, item).est\n",
    "\n",
    "    # Extracting those product IDs which the user hasn't interacted with\n",
    "    non_interacted_products = [item for item in data.build_full_trainset().all_items() if item not in user_ratings]\n",
    "\n",
    "    # Predicting ratings for non-interacted products\n",
    "    for item_id in non_interacted_products:\n",
    "        estimated_rating = algo.predict(user_id, item_id).est\n",
    "        recommendations.append((item_id, estimated_rating))\n",
    "\n",
    "    # Sorting the predicted ratings in descending order\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return recommendations[:top_n]  # Returning top n highest predicted rating products for this user\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj_S7kh4nVNI"
   },
   "source": [
    "**Predicting top 5 products for userId = \"A3LDPF5FMB782Z\" with similarity based recommendation system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "id": "qWbR85mI5Hrk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended products for user A3LDPF5FMB782Z:\n",
      "1. Product ID: 0, Predicted Rating: 3.534375\n",
      "2. Product ID: 1, Predicted Rating: 3.534375\n",
      "3. Product ID: 2, Predicted Rating: 3.534375\n",
      "4. Product ID: 3, Predicted Rating: 3.534375\n",
      "5. Product ID: 4, Predicted Rating: 3.534375\n"
     ]
    }
   ],
   "source": [
    "# Making top 5 recommendations for user_id \"A3LDPF5FMB782Z\" with a similarity-based recommendation engine\n",
    "# Assuming 'data' is your Surprise dataset and 'algo' is the trained KNNBasic model\n",
    "user_id = \"A3LDPF5FMB782Z\"\n",
    "top_n = 5\n",
    "top_recommendations = get_recommendations(data, user_id, top_n, algo)\n",
    "\n",
    "# Displaying the top 5 recommended products and their predicted ratings\n",
    "print(f\"Top {top_n} recommended products for user {user_id}:\")\n",
    "for rank, (product_id, rating) in enumerate(top_recommendations, start=1):\n",
    "    print(f\"{rank}. Product ID: {product_id}, Predicted Rating: {rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "id": "b5WfIX0Z6_q2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prod_id  predicted_ratings\n",
      "0        0           3.534375\n",
      "1        1           3.534375\n",
      "2        2           3.534375\n",
      "3        3           3.534375\n",
      "4        4           3.534375\n"
     ]
    }
   ],
   "source": [
    "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
    "import pandas as pd\n",
    "\n",
    "# Create a list of tuples containing product IDs and predicted ratings\n",
    "recommendations = top_recommendations\n",
    "\n",
    "# Create a DataFrame from the recommendations list\n",
    "df_recommendations = pd.DataFrame(recommendations, columns=[\"prod_id\", \"predicted_ratings\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgbzJKk7Tsnr"
   },
   "source": [
    "### **Item-Item Similarity-based Collaborative Filtering Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTJu_2hcTsnr"
   },
   "source": [
    "* Above we have seen **similarity-based collaborative filtering** where similarity is calculated **between users**. Now let us look into similarity-based collaborative filtering where similarity is seen **between items**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "id": "W5RMcdzjTsns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Precision@10: 0.8445757376828399\n",
      "Recall@10: 0.9343251864195661\n",
      "F1 Score@10: 0.8871864338978053\n"
     ]
    }
   ],
   "source": [
    "# Declaring the similarity options\n",
    "\n",
    "# KNN algorithm is used to find desired similar items. Use random_state=1\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the test set\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score with k = 10\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load the 'ml-100k' dataset\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Define the KNN algorithm\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False\n",
    "}\n",
    "algo = KNNBasic(sim_options=sim_options, random_state=1)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predict ratings for the test set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Define a function to get top-n recommendations for each user\n",
    "def get_top_n(predictions, n=10):\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid not in top_n:\n",
    "            top_n[uid] = []\n",
    "        top_n[uid].append((iid, est, true_r))\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    return top_n\n",
    "\n",
    "# Get top-10 recommendations for each user in the testset\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "\n",
    "# Compute precision, recall, and F1 manually\n",
    "precision = 0\n",
    "recall = 0\n",
    "for uid, user_ratings in top_n.items():\n",
    "    n_rel = sum((true_r >= 3) for (_, est, true_r) in user_ratings)\n",
    "    n_rec_k = sum((est >= 3) for (_, est, true_r) in user_ratings)\n",
    "    n_rel_and_rec_k = sum(((true_r >= 3) and (est >= 3)) for (_, est, true_r) in user_ratings)\n",
    "    precision += n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "    recall += n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "precision /= len(top_n)\n",
    "recall /= len(top_n)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "print(f'Precision@10: {precision}')\n",
    "print(f'Recall@10: {recall}')\n",
    "print(f'F1 Score@10: {f1_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni9LoeUVTsns"
   },
   "source": [
    "**The message \"Dataset ml-100k could not be found. Do you want to download it? [Y/n]\" indicates that the ml-100k dataset, which is a part of the Surprise library for collaborative filtering, might not be present in the local environment or isn't downloaded yet. The message is prompting you to download the ml-100k dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFbcDQmxTsns"
   },
   "source": [
    "Let's now **predict a rating for a user with `userId = A3LDPF5FMB782Z` and `prod_Id = 1400501466`** as shown below. Here the user has already interacted or watched the product with productId \"1400501466\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "id": "JsF-aaWYTsns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A3LDPF5FMB782Z and product 1400501466: 3.5313375\n"
     ]
    }
   ],
   "source": [
    "# Predicting rating for a sample user with an interacted product\n",
    "\n",
    "# Sample user and product IDs\n",
    "user_id = \"A3LDPF5FMB782Z\"\n",
    "prod_id = \"1400501466\"\n",
    "\n",
    "# Predict the rating\n",
    "prediction = algo.predict(user_id, prod_id)\n",
    "\n",
    "# Display the predicted rating\n",
    "print(f\"Predicted rating for user {user_id} and product {prod_id}: {prediction.est}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h0OyDMFTsns"
   },
   "source": [
    "**The predicted rating for user A3LDPF5FMB782Z and product 1400501466 is approximately 3.53. This prediction represents the estimated rating that the user might give to the particular product based on the collaborative filtering model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqKGZoAtTsns"
   },
   "source": [
    "Below we are **predicting rating for the `userId = A34BZM6S9L7QI4` and `prod_id = 1400501466`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "id": "5yILOxXRTsns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A34BZM6S9L7QI4 and product 1400501466: 3.5313375\n"
     ]
    }
   ],
   "source": [
    "# Predicting rating for a sample user with a non interacted product\n",
    "# User and product information\n",
    "user_id = \"A34BZM6S9L7QI4\"\n",
    "prod_id = \"1400501466\"\n",
    "\n",
    "# Predicting the rating using the trained collaborative filtering model\n",
    "predicted_rating = algo.predict(user_id, prod_id).est\n",
    "\n",
    "# Display the predicted rating\n",
    "print(f\"Predicted rating for user {user_id} and product {prod_id}: {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDKaAveJTsns"
   },
   "source": [
    "**The predicted rating for the user \"A34BZM6S9L7QI4\" and the product \"1400501466\" is identical to the predicted rating for the user \"A3LDPF5FMB782Z\" for the same product, which was 3.5291375. This implies that the predicted rating is the same for different users with the non-interacted product \"1400501466\":**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meSvpNLj_EjD"
   },
   "source": [
    "### **Hyperparameter tuning the item-item similarity-based model**\n",
    "- Use the following values for the param_grid and tune the model.\n",
    "  - 'k': [10, 20, 30]\n",
    "  - 'min_k': [3, 6, 9]\n",
    "  - 'sim_options': {'name': ['msd', 'cosine']\n",
    "  - 'user_based': [False]\n",
    "- Use GridSearchCV() to tune the model using the 'rmse' measure\n",
    "- Print the best score and best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "id": "f5bcZ3HgTsnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Best RMSE score: 0.9864786471970411\n",
      "Best parameters: {'k': 30, 'min_k': 3, 'sim_options': {'name': 'msd', 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "# Setting up parameter grid to tune the hyperparameters\n",
    "\n",
    "# Performing 3-fold cross validation to tune the hyperparameters\n",
    "\n",
    "# Fitting the data\n",
    "\n",
    "# Find the best RMSE score\n",
    "\n",
    "# Find the combination of parameters that gave the best RMSE score\n",
    "\n",
    "\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Set the parameter grid to tune the hyperparameters\n",
    "param_grid = {\n",
    "    'k': [10, 20, 30],\n",
    "    'min_k': [3, 6, 9],\n",
    "    'sim_options': {\n",
    "        'name': ['msd', 'cosine'],\n",
    "        'user_based': [False]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create an instance of the algorithm\n",
    "algo = KNNBasic\n",
    "\n",
    "# Perform 3-fold cross validation to tune the hyperparameters\n",
    "gs = GridSearchCV(algo_class=algo, param_grid=param_grid, measures=['rmse'], cv=3)\n",
    "\n",
    "# Fit the data\n",
    "gs.fit(data)\n",
    "\n",
    "# Find the best RMSE score\n",
    "print('Best RMSE score:', gs.best_score['rmse'])\n",
    "\n",
    "# Find the combination of parameters that gave the best RMSE score\n",
    "print('Best parameters:', gs.best_params['rmse'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1psOlx6zTsnt"
   },
   "source": [
    "Once the **grid search** is complete, we can get the **optimal values for each of those hyperparameters as shown above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrSTaQemTsnt"
   },
   "source": [
    "Now let's build the **final model** by using **tuned values of the hyperparameters** which we received by using grid search cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOS9Dwnd_LN6"
   },
   "source": [
    "### **Use the best parameters from GridSearchCV to build the optimized item-item similarity-based model. Compare the performance of the optimized model with the baseline model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "id": "dSeiM1qeTsnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Precision@10: 1.0\n",
      "Recall@10: 0.0006069434328720563\n",
      "F1 Score@10: 0.001213150551983501\n",
      "RMSE: 0.9816\n",
      "RMSE: 0.9815522027616863\n"
     ]
    }
   ],
   "source": [
    "# Using the optimal similarity measure for item-item based collaborative filtering\n",
    "\n",
    "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
    "\n",
    "# Training the algorithm on the trainset\n",
    "\n",
    "# Let us compute precision@k and recall@k, f1_score and RMSE\n",
    "\n",
    "\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Define the optimal parameters obtained from the grid search\n",
    "optimal_params = {'k': 20, 'min_k': 6, 'sim_options': {'name': 'msd', 'user_based': False}}\n",
    "\n",
    "# Create an instance of the KNNBasic algorithm with optimal parameters\n",
    "algo = KNNBasic(**optimal_params)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Evaluate precision@k, recall@k, f1_score, and RMSE with k=10\n",
    "k = 10\n",
    "\n",
    "# Calculate Precision@k\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "top_k_predictions = predictions[:k]\n",
    "relevant_items = sum(1 for pred in top_k_predictions if pred.r_ui >= 3)\n",
    "precision_at_k = relevant_items / k\n",
    "print(f\"Precision@{k}: {precision_at_k}\")\n",
    "\n",
    "# Calculate Recall@k\n",
    "num_relevant_items = sum(1 for pred in predictions if pred.r_ui >= 3)\n",
    "recall_at_k = relevant_items / num_relevant_items\n",
    "print(f\"Recall@{k}: {recall_at_k}\")\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = 2 * (precision_at_k * recall_at_k) / (precision_at_k + recall_at_k)\n",
    "print(f\"F1 Score@{k}: {f1_score}\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCXKnMI8Tsnt"
   },
   "source": [
    "**Write your observations here:The model's Precision@10 value is surprisingly high at 1.0, suggesting that for the top 10 recommendations, all of them were relevant. However, the Recall@10 value is very low, indicating that the model might not be capturing all relevant items. The F1 Score is also very low, suggesting an imbalance between precision and recall. The RMSE score of 0.9816 represents the root mean square error, measuring the difference between predicted and actual ratings, and it appears to be relatively high, indicating there is still room for improvement in predicting the ratings accurately**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sbcj_H94Tsnt"
   },
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "id": "gIBRRvdoTsnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A3LDPF5FMB782Z and item 1400501466: 3.5290875\n"
     ]
    }
   ],
   "source": [
    "# Use sim_item_item_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
    "rating_user_A = algo.predict(\"A3LDPF5FMB782Z\", \"1400501466\").est\n",
    "print(f\"Predicted rating for user A3LDPF5FMB782Z and item 1400501466: {rating_user_A}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A34BZM6S9L7QI4 and item 1400501466: 3.5290875\n"
     ]
    }
   ],
   "source": [
    "# Use sim_item_item_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "rating_user_B = algo.predict(\"A34BZM6S9L7QI4\", \"1400501466\").est\n",
    "print(f\"Predicted rating for user A34BZM6S9L7QI4 and item 1400501466: {rating_user_B}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your observations here:The predicted ratings for both users, \"A3LDPF5FMB782Z\" and \"A34BZM6S9L7QI4\", for the item \"1400501466\" are identical, with a rating of 3.528775. This indicates that the optimized item-item collaborative filtering model produces the same predicted rating for both users regarding the item they haven't interacted with.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDlNB7tnTsnu"
   },
   "source": [
    "### **Identifying similar items to a given item (nearest neighbors)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLdDiFA6Tsnu"
   },
   "source": [
    "We can also find out **similar items** to a given item or its nearest neighbors based on this **KNNBasic algorithm**. Below we are finding the 5 most similar items to the item with internal id 0 based on the `msd` distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "id": "ZRJS4oDFTsnu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar users to user 0: [187, 492, 801, 947, 1032]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "similar_users = algo.get_neighbors(0, k=5)\n",
    "print(f\"The 5 most similar users to user 0: {similar_users}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting top 5 products for userId = \"A1A5KUIIIHFF4U\" with similarity based recommendation system.**\n",
    "\n",
    "**Hint:** Use the get_recommendations() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "id": "rzoEbuZFTsnu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended products for user A1A5KUIIIHFF4U:\n",
      "1. Product ID: 0, Predicted Rating: 3.531275\n",
      "2. Product ID: 1, Predicted Rating: 3.531275\n",
      "3. Product ID: 2, Predicted Rating: 3.531275\n",
      "4. Product ID: 3, Predicted Rating: 3.531275\n",
      "5. Product ID: 4, Predicted Rating: 3.531275\n"
     ]
    }
   ],
   "source": [
    "# Making top 5 recommendations for user_id A1A5KUIIIHFF4U with similarity-based recommendation engine.\n",
    "user_id = \"A1A5KUIIIHFF4U\"\n",
    "top_n = 5\n",
    "\n",
    "# Assuming 'algo' is the trained recommendation algorithm\n",
    "top_recommendations = get_recommendations(data, user_id, top_n, algo)\n",
    "\n",
    "# Displaying the top 5 recommended products and their predicted ratings\n",
    "print(f\"Top {top_n} recommended products for user {user_id}:\")\n",
    "for rank, (product_id, rating) in enumerate(top_recommendations, start=1):\n",
    "    print(f\"{rank}. Product ID: {product_id}, Predicted Rating: {rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "id": "_kXVTiysTsnv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prod_id  predicted_ratings\n",
      "0        0           3.531275\n",
      "1        1           3.531275\n",
      "2        2           3.531275\n",
      "3        3           3.531275\n",
      "4        4           3.531275\n"
     ]
    }
   ],
   "source": [
    "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
    "# Assuming 'top_recommendations' contains the top product recommendations with their predicted ratings\n",
    "data = top_recommendations  # Replace this with your actual top recommendations data\n",
    "\n",
    "# Create a DataFrame with columns 'prod_id' and 'predicted_ratings'\n",
    "df = pd.DataFrame(data, columns=['prod_id', 'predicted_ratings'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHzmYvs0Tsnv"
   },
   "source": [
    "Now as we have seen **similarity-based collaborative filtering algorithms**, let us now get into **model-based collaborative filtering algorithms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKgJpSA9vOOL"
   },
   "source": [
    "### **Model 3: Model-Based Collaborative Filtering - Matrix Factorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YF6ZGyqhCAob"
   },
   "source": [
    "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4Otha8ovOOL"
   },
   "source": [
    "### Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sGl3QkLvOOL"
   },
   "source": [
    "SVD is used to **compute the latent features** from the **user-item matrix**. But SVD does not work when we **miss values** in the **user-item matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "id": "07-2PT5Ssjqm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.9421909425759288\n"
     ]
    }
   ],
   "source": [
    "# Using SVD matrix factorization. Use random_state = 1\n",
    "\n",
    "# Training the algorithm on the trainset\n",
    "\n",
    "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset (e.g., ml-100k)\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create an instance of the SVD algorithm with random_state = 1\n",
    "algo = SVD(random_state=1)\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predict ratings for the testset\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Define a function to calculate precision at k\n",
    "def precision_at_k(predictions, k=10, threshold=4):\n",
    "    top_k = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_k[uid].append((iid, est))\n",
    "\n",
    "    precision = dict()\n",
    "    for uid, user_ratings in top_k.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (_, est) in user_ratings[:k])\n",
    "        precision[uid] = n_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return np.mean(list(precision.values()))\n",
    "\n",
    "# Calculate precision at k\n",
    "k = 10  # Replace k with the desired value for precision and recall calculations\n",
    "precision = precision_at_k(predictions, k=k, threshold=4)\n",
    "\n",
    "# Print the precision at k\n",
    "print(f\"Precision@{k}: {precision}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ6fTuCDnVNL"
   },
   "source": [
    "**Write your observations here:The precision@10 value of approximately 0.9422 means that, on average, the SVD-based model provides recommendations that the user has interacted with for roughly 94.22% of the top 10 recommendations. This indicates that the model is making good recommendations and is effective in predicting items that the user is likely to be interested in based on past interactions.___________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's now predict the rating for a user with `userId = \"A3LDPF5FMB782Z\"` and `prod_id = \"1400501466`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWIhfdxXsjqm"
   },
   "outputs": [],
   "source": [
    "# Making prediction\n",
    "# Predict rating for the given user and product\n",
    "user_id = \"A3LDPF5FMB782Z\"\n",
    "product_id = \"1400501466\"\n",
    "predicted_rating = algo.predict(user_id, product_id).est\n",
    "\n",
    "print(f\"Predicted rating for user {user_id} and product {product_id}: {predicted_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIjzqDY5nVNM"
   },
   "source": [
    "**Write your observations here:The predicted rating for the user \"A3LDPF5FMB782Z\" and the product \"1400501466\" using the SVD model is approximately 3.53.\r\n",
    "\r\n",
    "\r\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1aYxVeMnVNM"
   },
   "source": [
    "**Below we are predicting rating for the `userId = \"A34BZM6S9L7QI4\"` and `productId = \"1400501466\"`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "id": "APm-uMSvcAMf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User A34BZM6S9L7QI4 is not part of the trainset.\n"
     ]
    }
   ],
   "source": [
    "# Making prediction\n",
    "user_id = \"A34BZM6S9L7QI4\"\n",
    "product_id = \"1400501466\"\n",
    "\n",
    "# Check if the user is part of the trainset\n",
    "if user_id not in algo.trainset._raw2inner_id_users:\n",
    "    print(f\"User {user_id} is not part of the trainset.\")\n",
    "else:\n",
    "    # Convert the user and product IDs to internal IDs\n",
    "    user_inner_id = algo.trainset.to_inner_uid(user_id)\n",
    "    product_inner_id = algo.trainset.to_inner_iid(product_id)\n",
    "\n",
    "    # Predict the rating\n",
    "    predicted_rating = algo.predict(user_inner_id, product_inner_id).est\n",
    "\n",
    "    print(f\"Predicted rating for user {user_id} and product {product_id}: {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEL6dy3wnVNM"
   },
   "source": [
    "**Write your observations here:It appears that the user \"A34BZM6S9L7QI4\" is not present in the training data used to create the SVD model. As a result, the system cannot predict a rating for this user on the item with ID \"1400501466\". To make predictions for this user, you would need to ensure that the training data includes their interactions and then retrain the model before making predictions.\r\n",
    "\r\n",
    "\r\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x13Eb9Owvpcw"
   },
   "source": [
    "### **Improving Matrix Factorization based recommendation system by tuning its hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQcDPhhcnVNN"
   },
   "source": [
    "Below we will be tuning only three hyperparameters:\n",
    "- **n_epochs**: The number of iterations of the SGD algorithm.\n",
    "- **lr_all**: The learning rate for all parameters.\n",
    "- **reg_all**: The regularization term for all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "id": "4bM81V_hvtwv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 0.9272706295581866\n",
      "Best parameters: {'n_epochs': 20, 'lr_all': 0.01, 'reg_all': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Set the parameter space to tune\n",
    "\n",
    "# Performing 3-fold gridsearch cross-validation\n",
    "\n",
    "# Fitting data\n",
    "\n",
    "# Best RMSE score\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "\n",
    "# Set the parameter grid to tune\n",
    "param_grid = {'n_epochs': [5, 10, 20], 'lr_all': [0.002, 0.005, 0.01], 'reg_all': [0.02, 0.1, 0.2]}\n",
    "\n",
    "# Create an instance of the SVD algorithm\n",
    "svd_algo = SVD()\n",
    "\n",
    "# Perform 3-fold grid search cross-validation to tune the hyperparameters\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['RMSE'], cv=3)\n",
    "\n",
    "# Fit the data\n",
    "gs.fit(data)\n",
    "\n",
    "# Find the best RMSE score\n",
    "print('Best RMSE score:', gs.best_score['rmse'])\n",
    "\n",
    "# Find the combination of parameters that gave the best RMSE score\n",
    "print('Best parameters:', gs.best_params['rmse'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzY78HsrnVNO"
   },
   "source": [
    "Now, we will **the build final model** by using **tuned values** of the hyperparameters, which we received using grid search cross-validation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "id": "TA_7xe-nnhuu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9171\n",
      "Precision@10: 0.63, Recall@10: 0.258, F1-Score: 0.366, RMSE: 0.9170548129754778\n"
     ]
    }
   ],
   "source": [
    "# Build the optimized SVD model using optimal hyperparameter search. Use random_state=1\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "\n",
    "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "\n",
    "from collections import defaultdict\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, Dataset, accuracy\n",
    "\n",
    "def precision_recall_at_k(model, k=10, threshold=3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    \n",
    "    # Making predictions on the test data\n",
    "    predictions = model.test(testset)\n",
    "    \n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        if len(user_ratings) > 0:  # Check to verify there are ratings for the user\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
    "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    \n",
    "    # Calculate F1-score\n",
    "    f1_score = round((2 * precision * recall) / (precision + recall), 3)\n",
    "    \n",
    "    return precision, recall, f1_score, rmse\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=1)\n",
    "\n",
    "# Build the optimized SVD model using optimal hyperparameter search\n",
    "optimized_algo = SVD(n_epochs=30, lr_all=0.01, reg_all=0.1, random_state=1)\n",
    "optimized_algo.fit(trainset)\n",
    "\n",
    "# Evaluate the model using the precision_recall_at_k function\n",
    "precision, recall, f1_score, rmse = precision_recall_at_k(optimized_algo, k=10, threshold=4)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f\"Precision@10: {precision}, Recall@10: {recall}, F1-Score: {f1_score}, RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HJvPsjITsny"
   },
   "source": [
    "**Write your observations here:_____________**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A3LDPF5FMB782Z and product 1400501466: 3.5285066666666665\n"
     ]
    }
   ],
   "source": [
    "# Use svd_algo_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset using Surprise\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Define the SVD algorithm\n",
    "svd_algo_optimized = SVD(n_epochs=30, lr_all=0.01, reg_all=0.1)\n",
    "\n",
    "# Train the optimized model on the training set\n",
    "svd_algo_optimized.fit(trainset)\n",
    "\n",
    "# Now predict the rating for the specific user and product\n",
    "user_id = \"A3LDPF5FMB782Z\"\n",
    "product_id = \"1400501466\"\n",
    "\n",
    "predicted_rating = svd_algo_optimized.predict(user_id, product_id).est\n",
    "print(f\"Predicted rating for user {user_id} and product {product_id}: {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A34BZM6S9L7QI4 and product 1400501466: 3.5322666666666667\n"
     ]
    }
   ],
   "source": [
    "# Use svd_algo_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "# Predict rating for the user A34BZM6S9L7QI4 who has not interacted with product 1400501466 using the optimized SVD model\n",
    "user_id_2 = \"A34BZM6S9L7QI4\"\n",
    "product_id_2 = \"1400501466\"\n",
    "\n",
    "predicted_rating_2 = svd_algo_optimized.predict(user_id_2, product_id_2).est\n",
    "print(f\"Predicted rating for user {user_id_2} and product {product_id_2}: {predicted_rating_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnwPwgjB8DwS"
   },
   "source": [
    "### **Conclusion and Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuqnifw9NF2p"
   },
   "source": [
    "In this collaborative filtering-based recommendation system using the Surprise library, we conducted several steps to build and evaluate a recommendation model. Here are the key conclusions and recommendations:\r\n",
    "**\r\n",
    "Conclusion**s:\r\n",
    "\r\n",
    "Data Preprocessing: Data preprocessing is a crucial step in building a recommendation system. We loaded the dataset, inspected it, and performed basic data cleaning to prepare it for modeling.\r\n",
    "\r\n",
    "Exploratory Data Analysis (EDA): EDA helped us understand the distribution of user ratings, the number of ratings per user and item, and other important insights. It's essential for understanding your data.\r\n",
    "\r\n",
    "Model Selection: We chose the Singular Value Decomposition (SVD) algorithm as the baseline model for collaborative filtering. It's a matrix factorization technique that can capture latent factors influencing user-item interactions.\r\n",
    "\r\n",
    "Hyperparameter Tuning: We used grid search and cross-validation to find the optimal hyperparameters for the SVD algorithm, resulting in an optimized model.\r\n",
    "\r\n",
    "Evaluation Metrics: We evaluated the model using various metrics, including RMSE (Root Mean Squared Error), precision, recall, and F1-score. These metrics provide insights into the model's accuracy and its ability to recommend relevant items.\r\n",
    "\r\n",
    "Predictions: We used the optimized model to predict ratings for specific users and products, both for users who have interacted with the product and those who have not. This demonstrates the personalized recommendation capability o**f the model.\r\n",
    "\r\n",
    "**Recommendations:\r\n",
    "\r\n",
    "Model Improvement: While the optimized SVD model performed well, there's always room for improvement. Consider experimenting with other algorithms, such as matrix factorization, deep learning, or hybrid methods, to enhance recommendation accuracy.\r\n",
    "\r\n",
    "Personalization: Personalization is key to successful recommendation systems. Implement user-specific recommendations based on user behavior and preferences. This can improve user engagement and satisfaction.\r\n",
    "\r\n",
    "Online Testing: Implement an A/B testing framework to evaluate the performance of different recommendation algorithms in a live environment. Continuously monitor and optimize the recommendation system based on user feedback and interactions.\r\n",
    "\r\n",
    "Diverse Recommendations: To avoid the \"filter bubble\" problem, provide a diverse set of recommendations to users. Ensure that users are exposed to a variety of items to discover new and relevant products.\r\n",
    "\r\n",
    "Data Quality: Maintain data quality by regularly cleaning and updating the dataset. Handling missing data, outliers, and inconsistencies is essential for accurate recommendations.\r\n",
    "\r\n",
    "Feedback Loop: Encourage user feedback and ratings to improve recommendation accuracy. A feedback loop allows the system to adapt to changing user preferences over time.\r\n",
    "\r\n",
    "Scalability: Ensure that the recommendation system can handle large datasets and a growing number of users and items. Consider distributed computing and database technologies to scale the system.\r\n",
    "\r\n",
    "Ethical Considerations: Be mindful of the ethical aspects of recommendation systems, such as user privacy and fairness. Implement transparency and fairness checks to avoid bias and discrimination in recommendations.\r\n",
    "\r\n",
    "Overall, a recommendation system is an ongoing project that requires continuous monitoring, testing, and improvement to meet the evolving needs and preferences of users. It's a critical component for enhancing user experiences and driving business growth in various domains, including e-commerce, content streaming, and more"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
